{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hHzMBHDD5JqM",
        "outputId": "cca47d4a-f1d3-4344-84db-799775d639ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+---------------------------------+------------------+--------------------+---------------------+\n",
            "|   Data size | Configuration                   |   Training error |   Validation error | Time of execution   |\n",
            "+=============+=================================+==================+====================+=====================+\n",
            "|        1000 | 1 hidden layer 4 nodes          |           0.238  |             0.2429 | 0.071s              |\n",
            "+-------------+---------------------------------+------------------+--------------------+---------------------+\n",
            "|       10000 | 1 hidden layer 4 nodes          |           0.0128 |             0.0142 | 0.495s              |\n",
            "+-------------+---------------------------------+------------------+--------------------+---------------------+\n",
            "|      100000 | 1 hidden layer 4 nodes          |           0.0006 |             0.0006 | 6.255s              |\n",
            "+-------------+---------------------------------+------------------+--------------------+---------------------+\n",
            "|        1000 | 2 hidden layers of 4 nodes each |           0.246  |             0.2383 | 0.065s              |\n",
            "+-------------+---------------------------------+------------------+--------------------+---------------------+\n",
            "|       10000 | 2 hidden layers of 4 nodes each |           0.0012 |             0.0021 | 1.149s              |\n",
            "+-------------+---------------------------------+------------------+--------------------+---------------------+\n",
            "|      100000 | 2 hidden layers of 4 nodes each |           0.0007 |             0.0007 | 6.365s              |\n",
            "+-------------+---------------------------------+------------------+--------------------+---------------------+\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "import time\n",
        "from tabulate import tabulate\n",
        "\n",
        "# Load the data\n",
        "pima_df = pd.read_csv(\"week_11_data_pima.csv\")\n",
        "\n",
        "# Prepare the data\n",
        "X = pima_df.drop('outcome', axis=1)\n",
        "y = pima_df['outcome']\n",
        "\n",
        "# Split the data\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Scale the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_val_scaled = scaler.transform(X_val)\n",
        "\n",
        "# Define configurations\n",
        "configs = [\n",
        "    {'data_size': 1000, 'hidden_layers': (4,), 'name': '1 hidden layer 4 nodes'},\n",
        "    {'data_size': 10000, 'hidden_layers': (4,), 'name': '1 hidden layer 4 nodes'},\n",
        "    {'data_size': 100000, 'hidden_layers': (4,), 'name': '1 hidden layer 4 nodes'},\n",
        "    {'data_size': 1000, 'hidden_layers': (4, 4), 'name': '2 hidden layers of 4 nodes each'},\n",
        "    {'data_size': 10000, 'hidden_layers': (4, 4), 'name': '2 hidden layers of 4 nodes each'},\n",
        "    {'data_size': 100000, 'hidden_layers': (4, 4), 'name': '2 hidden layers of 4 nodes each'},\n",
        "]\n",
        "\n",
        "results = []\n",
        "\n",
        "for config in configs:\n",
        "    # Prepare data subset based on data_size\n",
        "    train_size = min(config['data_size'], len(X_train_scaled))\n",
        "\n",
        "    # Sample from training data if needed\n",
        "    if train_size < len(X_train_scaled):\n",
        "        indices = np.random.choice(len(X_train_scaled), train_size, replace=False)\n",
        "        X_train_subset = X_train_scaled[indices]\n",
        "        y_train_subset = y_train.iloc[indices]\n",
        "    else:\n",
        "        # If dataset is smaller than requested, use repeated sampling\n",
        "        repeats = train_size // len(X_train_scaled)\n",
        "        remainder = train_size % len(X_train_scaled)\n",
        "\n",
        "        X_train_subset = np.vstack([X_train_scaled] * repeats)\n",
        "        y_train_subset = pd.concat([y_train] * repeats)\n",
        "\n",
        "        if remainder > 0:\n",
        "            indices = np.random.choice(len(X_train_scaled), remainder, replace=False)\n",
        "            X_train_subset = np.vstack([X_train_subset, X_train_scaled[indices]])\n",
        "            y_train_subset = pd.concat([y_train_subset, y_train.iloc[indices]])\n",
        "\n",
        "    # Create and train model\n",
        "    model = MLPClassifier(\n",
        "        hidden_layer_sizes=config['hidden_layers'],\n",
        "        activation='relu',  # Using ReLU activation\n",
        "        solver='adam',\n",
        "        max_iter=500,\n",
        "        random_state=42,\n",
        "        early_stopping=True,\n",
        "        validation_fraction=0.1,\n",
        "        n_iter_no_change=10\n",
        "    )\n",
        "\n",
        "    # Time the training\n",
        "    start_time = time.time()\n",
        "    model.fit(X_train_subset, y_train_subset)\n",
        "    end_time = time.time()\n",
        "\n",
        "    # Make predictions\n",
        "    train_pred = model.predict(X_train_subset)\n",
        "    val_pred = model.predict(X_val_scaled)\n",
        "\n",
        "    # Calculate accuracy (using 1-accuracy for error)\n",
        "    train_error = 1 - accuracy_score(y_train_subset, train_pred)\n",
        "    val_error = 1 - accuracy_score(y_val, val_pred)\n",
        "    execution_time = end_time - start_time\n",
        "\n",
        "    results.append([\n",
        "        config['data_size'],\n",
        "        config['name'],\n",
        "        f\"{train_error:.4f}\",\n",
        "        f\"{val_error:.4f}\",\n",
        "        f\"{execution_time:.3f}s\"\n",
        "    ])\n",
        "\n",
        "# Display results in table format\n",
        "headers = [\"Data size\", \"Configuration\", \"Training error\", \"Validation error\", \"Time of execution\"]\n",
        "print(tabulate(results, headers=headers, tablefmt=\"grid\"))"
      ]
    }
  ]
}